#!/bin/bash 
#SBATCH  -C gpu -N 1 -A nintern
# SBATCH --ntasks-per-node=4
# SBATCH  --time=28:00 -q debug
#SBATCH --time 23:58:00  -q regular 
#SBATCH --output=out/%j.out
#SBATCH  --licenses=scratch
# - - - E N D    O F    SLURM    C O M M A N D S

set -u ;  # exit  if you try to use an uninitialized variable

#
# cray-mpich and cray-libsci conflict with openmpi so unload them
#
#module unload cray-mpich
#module unload cray-libsci
#module use /global/common/software/m3169/perlmutter/modulefiles
#module load openmpi

expN=${1:-mar34q}
trg=${2:-adjGPU}
shots=${3:-10240}
if [ "$trg" == "par-cpu" ]; then
    backend='qiskit-cpu'
elif [ "$trg" == "par-gpu" ]; then
     backend="nvidia-mqpu"  # all 4 GPUs in parallel
elif [ "$trg" == "adj-gpu" ]; then
    backend="nvidia-mgpu"
fi

#env
echo S:  expN=$expN  backend=$backend    expN=$expN   user=$USER
N=${SLURM_NNODES:-1}
T=${SLURM_NTASKS_PER_NODE:-1}
G=$(( T * N ))

echo S: head:`hostname` N=$N  T=$T  G=$G

#.....  define Podman image
export PODMANHPC_ADDITIONAL_STORES=/dvs_ro/cfs/cdirs/nintern/gzquse/podman_common/
IMG=gzquse/cudaquanmpi-qiskit:p6
echo S: head:`hostname`  use image $IMG

#..... input data:
if [ "$USER" == "balewski" ]; then  #Jan
    CFSH=/global/cfs/cdirs/mpccc/balewski
    #BASE_PATH=${CFSH}/quantDataVault2024/dataCudaQ_june28 - good campaign
    BASE_PATH=${CFSH}/quantDataVault2024/dataCudaQ_July8
    DATA_SRC=${CFSH}/2024_martin_gradient
elif [ "$USER" == "gzquse" ]; then    # Martin
    CFSH=/pscratch/sd/g/gzquse
    # remember to change this line
    BASE_PATH=${CFSH}/quantDataVault2024/dataCudaQ_July4
    DATA_SRC=${CFSH}/GRADIENT_IMAGE
fi

#...  sandbox code
jobId=${SLURM_JOBID:27658327}
wrkPath=$SCRATCH/jobs_cudaq/$jobId

echo wrkPath=$wrkPath
mkdir -p $wrkPath
cp -rp ../toolbox distributed *py  wrapPodman-martin.sh batchPodman-martin.slr $wrkPath/
cd $wrkPath

# .... task to be executed by Podman
#1CMD="mpirun -np 4 python3 -u  ./run_gateList.py  --expName $expN --backend $backend   --numShots $shots  --basePath /myData  "

# CPU version uses srun  for mutiple tasks
CMD=" python3 -u  ./run_gateList.py  --expName $expN --backend $backend   --numShots $shots  --basePath /myData  "

if [ "$trg" == "adj-gpu" ]; then
    CMD=" mpirun -np 4 "$CMD
    # drop it after image is updated:
    CMD=" pip3 install --user mpi4py; "$CMD
fi

#CMD="mpirun -np 4 python3 -u  ./cuquantum_backends.py  "
# spare: 

echo S: CMD=$CMD
#pwd
#ls
#nvidia-smi

#..... fire the task ....
srun -l --mpi=pmix -n $G ./wrapPodman-martin.sh $IMG " $CMD " $wrkPath  $BASE_PATH
echo S:done ; date 

#Cancel all my jobs:
#  squeue -u $USER -h | awk '{print $1}' | xargs scancel

# all jobs in the qos
#  squeue --qos=gpu_shared -o "%.7i %.10P %.12j %.8u %.2t %.10M %.6D %R %.20N"

